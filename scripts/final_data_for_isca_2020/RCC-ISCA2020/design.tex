\section{System Overview}
%\vspace{-2mm}
%-- Similar to Section 2 of VLDB, need a figure similar to Figure 1 of that paper

% \vspace{-2mm}
\subsection{Principles and Architecture}
%\vspace{-2mm}


%-- Based on the figure, explain the overall design flow shared by all protocols. I understand that the design is based on ROCC, so the figure will be  different from VLDB. You need to draw a figure based on ROCC framework and describe the common interface and components for all protocols. 

%In order to implement and evaluate representative concurrency control protocols using RDMA primitives, we designed a framework called \textbf{\system}. 
\setlength{\intextsep}{2pt}%
\setlength{\columnsep}{8pt}%
\begin{wrapfigure}[10]{r}{0.60\linewidth}
%\begin{figure}[t]
    \centering
    \vspace{-0.2cm}
    \includegraphics[width=\linewidth]{images/System.pdf}
    \vspace{-6mm}
    \caption{RCC Framework Overview}
    \vspace{-0.8cm}
    \label{fig:system}
\end{wrapfigure}
Figure~\ref{fig:system} shows the overview of 
\projectname, which runs on multiple symmetric distributed nodes,
each contains a configurable number of server threads 
to process transactions. A client thread continuously sends transaction requests to a random transaction processing thread in the cluster. The stats thread is used to collect the statistics (e.g., the number of committed transaction) generated by each processing thread. The QP thread is used to bootstrap RDMA connection by establishing the pairing of RDMA QPs using TCP connections. 

\projectname uses co-routines as an key optimization technique~\cite{kalia2016fasst} for hiding network latency. To this end, each thread starts an {\em event handling} co-routine and a number of {\em transaction coordination} co-routines. An event handling co-routine continuously checks and handles network-triggered events such as polled completions or {memory-triggered events} such as the releasing of a local lock. A transaction coordination co-routine is where a transaction is logically executed.

In \projectname, the distributed in-memory database is implemented as a distributed key-value store which can be accessed either locally or remotely via a key and table ID. In addition to the in-memory database, each protocol has its protocol-specific metadata to serialize transaction execution. For some protocol like \calvin, protocol-specific RDMA buffers are required for collecting transaction inputs and forwarding local reads. 

%\vspace{-2mm}
\subsection{Transaction and Execution Model}
%\vspace{-2mm}

%-- See VLDB paper, but our model is **not** based on stored procedure. Explain our model here: how data are distributed? server/client. (Also check OSDI paper, it also mentioned ``symmetric model''..)
\projectname employs a symmetric model to execute transactions: each node serves as both a client and a transaction processing server. As shown in Figure~\ref{fig:system}, each transaction coordination co-routine is responsible for executing a transaction at any time. 
We use {\em coordinator} to refer to the co-routine which receives transaction requests from some local or remote client thread and orchestrates transactional activities in the cluster. We use {\em participant} to refer to a machine where there is a record to be accessed by some transaction. When a 
participant receives a RPC request, its event handling co-routine will be invoked to process the request locally.
When a participant receives a RDMA one-sided 
operation, its RNIC is responsible for accessing the memory without interrupting the CPU.

In \projectname, the in-memory database keeps all records. Since one-sided operations can only access remote memory by leveraging the pre-computed remote offsets. To reduce the number of one-sided operations involved in retrieving metadata, they are placed physically together with the record
as shown in Figure~\ref{fig:metadata}.
A {\em record} refers to the 
actual data and a {\em tuple} refers to record associated 
with the relevant metadata.


A transaction contains reads and writes of 
records that are performed atomically.
The execution of a transaction contains three
stages~\footnote{We use this assumption for simplicity. The implementation
can also be applied to transactions with multiple fetching and execution stages.}: 
1) {\em fetching}, in which a read/write operation fetches the record and/or metadata if needed;
2) {\em execution}, in which a transaction  performs the actual computation locally using the record just fetched; and 
3) {\em commit}, in which a transaction checks the metadata to find out if the transaction execution is serializable. 




\begin{comment}
In our \projectname, 
%we assume that each transaction will only have one commit stage, which means the transaction will end after committing. To make our introduction more concise, 
we assume that there is just one data fetching and execution stage. However the implementation
can be applied to transactions with multiple date fetching and execution stages.
The execution of each read and write is
composed of three stages:
1) {\em access} the data and add the operation into {\em read or write set};
2) {\em validate} the operation; and 
3) {\em commit} the write set when the transaction

Generally, a transaction execution is divided into three stages, and consists of write or read operations. The first stage is \textbf{fetching}, where the write or read operation  fetches the needed record. The second stage is \textbf{execution}, where the transaction will do the actual computation locally using the record just fetched. The third stage is \textbf{commit}. In this stage, the transaction checks the metadata to find out if the execution was valid. after which it commits the updated records as well as their corresponding metadata.
\end{comment}

%\vspace{-2mm}
\subsection{RDMA Primitives and Optimizations}
%\vspace{-2mm}

% -- See 3.1 and 3.2 of OSDI, try to be brief since they are not our contribution. Also mention any optimizations we have proposed and validated to work well. 



We uses two-sided RDMA primitives (i.e., \texttt{SEND/RECV}) over UD QP in the
implementation of RPC. From ~\cite{kalia2016fasst},
two-sided primitives over UD QPs have better performance for symmetric transaction systems \red{than one-sided} and UD mode is much more reliable than expected with RDMA network's lossless link layer. \cite{wei2018deconstructing} further confirms the unsuitability of one-sided primitives to implement fast RPC compared to two-sided ones. 


Figure~\ref{fig:two-vs-one-primitives} illustrates the two types of communications in \projectname by each concurrency control protocol. In two-sided RPC, a coordinator first sends a memory-mapped IO (MMIO) to the RNIC, which will \texttt{SEND} a RPC request to the receiver's RNIC. After the corresponding participant \texttt{RECV}s the request, its CPU will poll a completion event, 
which will trigger a pre-registered handler function to process the request and send back a reply using similar verbs. In one-sided communication, after the participant receives a one-sided op request (i.e., \texttt{READ}, \texttt{WRITE}, \texttt{ATOMIC}), its RNIC will access local memory using a Direct Memory Access (DMA). The completion is signaled when the coordinator polls if it is interested in the completion event.

\setlength{\intextsep}{2pt}%
\setlength{\columnsep}{8pt}%
\begin{wrapfigure}[8]{r}{.55\linewidth}
%\begin{figure}[htp]
    \centering
    \vspace{-0.2cm}
    \includegraphics[width=\linewidth]{images/two_vs_one.pdf}
    \vspace{-1cm}
    \caption{Two-sided v.s. one-sided primitives}
    \vspace{-0.4cm}
    \label{fig:two-vs-one-primitives}
\end{wrapfigure}
MMIO is an expensive operation to notify RNIC of a request fetching event. Therefore using one MMIO for a batch of RDMA requests can effectively save PCIe bandwidth and improve the performance of transaction systems~\cite{wei2018deconstructing}. Meanwhile, having multiple outstanding  requests on the fly can help save the waiting time of request completions, thus reducing the latency of remote transaction~\cite{wei2018deconstructing}. Besides co-routines, \projectname uses similar techniques as important optimizations.