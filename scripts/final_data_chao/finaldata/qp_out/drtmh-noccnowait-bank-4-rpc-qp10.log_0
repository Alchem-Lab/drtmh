NOCC started with program [noccnowait-rpc]. at 13-02-2020 07:32:36
[bench_runner.cc:327] Use TCP port 8835
[0m[bench_runner.cc:349] use scale factor: 24; with total 8 threads.
[0m[view.h:48] Start with 0 backups.
[0m[view.cc:10] total 4 backups to assign
[0m[Bank]: check workload 0, 0, 0, 0, 0, 0, 100
[util.cc:161] malloc_huge_pages: size = 13883146240huge_page_sz = 2097152flag = 1
[0m[util.cc:175] huge page alloc failed!
[0m[librdma] get device name mlx5_0, idx 0
[librdma] : Device 0 has 1 ports
[bench_runner.cc:154] Total logger area 0.00390625G.
[0m[bench_runner.cc:165] add RDMA store size 9.76562G.
[0m[bench_runner.cc:174] [Mem] RDMA heap size 3.15819G.
[0m[util.cc:161] malloc_huge_pages: size = 314572800huge_page_sz = 2097152flag = 1
[0m[util.cc:175] huge page alloc failed!
[0m[util.cc:161] malloc_huge_pages: size = 314572800huge_page_sz = 2097152flag = 1
[0m[util.cc:175] huge page alloc failed!
[0m[util.cc:161] malloc_huge_pages: size = 314572800huge_page_sz = 2097152flag = 1
[0m[util.cc:175] huge page alloc failed!
[0m[bank_main.cc:236] finish loading zipfian 0
[0m[Bank], total 9600000 accounts loaded
[bank_main.cc:337] check cv balance 46280
[0m[Runner] local db size: 293.449 MB
[Runner] Cache size: 0 MB
[bench_listener2.cc:64] try log results to ./results/noccnowait-rpc_bank_4_8_10_100.log
[0mregisterring 13883146240registerring 13883146240registerring 13883146240registerring 13883146240registerring 13883146240registerring 13883146240registerring 13883146240registerring 13883146240worker: 0 binding 0
worker: 7 binding 14
worker: 2 binding 4
[Global sequence running] !
worker: 3 binding 6
worker: 4 binding 8
worker: 1 binding 2
worker: 6 binding 12
worker: 5 binding 10
[bench_listener2.cc:73] New monitor running!
[0mregisterring 13883146240registerring 13883146240threadid=7: all 4 qps connected
threadid=3: all 4 qps connected
threadid=5: all 4 qps connected
threadid=0: all 4 qps connected
threadid=6: all 4 qps connected
threadid=4: all 4 qps connected
threadid=9: all 4 qps connected
threadid=1: all 4 qps connected
2: 3 out of 4 qps connected. Retry connecting qps...
threadid=1: all 4 qps connected
threadid=2: all 4 qps connected
threadid=2: all 4 qps connected
10: 2 out of 4 qps connected. Retry connecting qps...
7: 3 out of 4 qps connected. Retry connecting qps...
0: 3 out of 4 qps connected. Retry connecting qps...
3: 3 out of 4 qps connected. Retry connecting qps...
4: 3 out of 4 qps connected. Retry connecting qps...
6: 3 out of 4 qps connected. Retry connecting qps...
threadid=7: all 4 qps connected
9: 3 out of 4 qps connected. Retry connecting qps...
5: 3 out of 4 qps connected. Retry connecting qps...
threadid=4: all 4 qps connected
threadid=3: all 4 qps connected
threadid=9: all 4 qps connected
threadid=10: all 4 qps connected
threadid=5: all 4 qps connected
threadid=6: all 4 qps connected
threadid=0: all 4 qps connected
threadid=7: all 4 qps connected
threadid=4: all 4 qps connected
threadid=9: all 4 qps connected
threadid=5: all 4 qps connected
threadid=3: all 4 qps connected
threadid=6: all 4 qps connected
threadid=0: all 4 qps connected
threadid=10: all 4 qps connected
1: 1 out of 4 qps connected. Retry connecting qps...
threadid=1: all 4 qps connected
2: 1 out of 4 qps connected. Retry connecting qps...
threadid=2: all 4 qps connected
7: 2 out of 4 qps connected. Retry connecting qps...
threadid=7: all 4 qps connected
4: 2 out of 4 qps connected. Retry connecting qps...
9: 2 out of 4 qps connected. Retry connecting qps...
3: 1 out of 4 qps connected. Retry connecting qps...
5: 2 out of 4 qps connected. Retry connecting qps...
threadid=9: all 4 qps connected
threadid=5: all 4 qps connected
threadid=4: all 4 qps connected
threadid=3: all 4 qps connected
6: 2 out of 4 qps connected. Retry connecting qps...
10: 1 out of 4 qps connected. Retry connecting qps...
threadid=9: all 4 qps connected
0: 3 out of 4 qps connected. Retry connecting qps...
threadid=0: all 4 qps connected
threadid=5: all 4 qps connected
threadid=6: all 4 qps connected
threadid=10: all 4 qps connected
1: 3 out of 4 qps connected. Retry connecting qps...
threadid=1: all 4 qps connected
threadid=0: all 4 qps connected
threadid=6: all 4 qps connected
threadid=1: all 4 qps connected
2: 3 out of 4 qps connected. Retry connecting qps...
threadid=2: all 4 qps connected
threadid=2: all 4 qps connected
7: 3 out of 4 qps connected. Retry connecting qps...
threadid=7: all 4 qps connected
4: 3 out of 4 qps connected. Retry connecting qps...
threadid=4: all 4 qps connected
threadid=7: all 4 qps connected
threadid=4: all 4 qps connected
3: 3 out of 4 qps connected. Retry connecting qps...
threadid=3: all 4 qps connected
9: 1 out of 4 qps connected. Retry connecting qps...
threadid=9: all 4 qps connected
threadid=3: all 4 qps connected
5: 2 out of 4 qps connected. Retry connecting qps...
10: 3 out of 4 qps connected. Retry connecting qps...
threadid=10: all 4 qps connected
threadid=5: all 4 qps connected
0: 2 out of 4 qps connected. Retry connecting qps...
1: 1 out of 4 qps connected. Retry connecting qps...
6: 1 out of 4 qps connected. Retry connecting qps...
threadid=0: all 4 qps connected
threadid=9: all 4 qps connected
threadid=10: all 4 qps connected
threadid=1: all 4 qps connected
threadid=6: all 4 qps connected
2: 1 out of 4 qps connected. Retry connecting qps...
threadid=2: all 4 qps connected
threadid=2: all 4 qps connected
7: 1 out of 4 qps connected. Retry connecting qps...
4: 1 out of 4 qps connected. Retry connecting qps...
threadid=7: all 4 qps connected
threadid=4: all 4 qps connected
3: 1 out of 4 qps connected. Retry connecting qps...
5: 3 out of 4 qps connected. Retry connecting qps...
threadid=5: all 4 qps connected
threadid=3: all 4 qps connected
10: 1 out of 4 qps connected. Retry connecting qps...
0: 3 out of 4 qps connected. Retry connecting qps...
9: 2 out of 4 qps connected. Retry connecting qps...
1: 2 out of 4 qps connected. Retry connecting qps...
6: 2 out of 4 qps connected. Retry connecting qps...
threadid=0: all 4 qps connected
threadid=5: all 4 qps connected
threadid=9: all 4 qps connected
threadid=1: all 4 qps connected
threadid=6: all 4 qps connected
threadid=10: all 4 qps connected
2: 1 out of 4 qps connected. Retry connecting qps...
threadid=0: all 4 qps connected
threadid=1: all 4 qps connected
threadid=10: all 4 qps connected
threadid=2: all 4 qps connected
threadid=6: all 4 qps connected
threadid=9: all 4 qps connected
threadid=2: all 4 qps connected
7: 2 out of 4 qps connected. Retry connecting qps...
threadid=7: all 4 qps connected
4: 3 out of 4 qps connected. Retry connecting qps...
threadid=4: all 4 qps connected
3: 3 out of 4 qps connected. Retry connecting qps...
threadid=3: all 4 qps connected
threadid=3: all 4 qps connected
5: 2 out of 4 qps connected. Retry connecting qps...
0: 2 out of 4 qps connected. Retry connecting qps...
1: 2 out of 4 qps connected. Retry connecting qps...
9: 2 out of 4 qps connected. Retry connecting qps...
10: 2 out of 4 qps connected. Retry connecting qps...
6: 1 out of 4 qps connected. Retry connecting qps...
threadid=0: all 4 qps connected
threadid=10: all 4 qps connected
2: 2 out of 4 qps connected. Retry connecting qps...
7: 3 out of 4 qps connected. Retry connecting qps...
threadid=7: all 4 qps connected
4: 3 out of 4 qps connected. Retry connecting qps...
threadid=4: all 4 qps connected
threadid=5: all 4 qps connected
threadid=1: all 4 qps connected
threadid=6: all 4 qps connected
threadid=9: all 4 qps connected
threadid=2: all 4 qps connected
threadid=0: all 4 qps connected
threadid=5: all 4 qps connected
3: 2 out of 4 qps connected. Retry connecting qps...
10: 3 out of 4 qps connected. Retry connecting qps...
7: 3 out of 4 qps connected. Retry connecting qps...
4: 3 out of 4 qps connected. Retry connecting qps...
threadid=4: all 4 qps connected
threadid=10: all 4 qps connected
threadid=7: all 4 qps connected
threadid=3: all 4 qps connected
threadid=1: all 4 qps connected
[bench_worker.h:160] Use RDMA for logging.
[0m[nowait_rdma.h:318] Use one-sided for read.
[0m[rworker.cc:47] Worker 9 on cpu 18with cor id 0
[0mthreadid=6: all 4 qps connected
threadid=10: all 4 qps connected
[bench_listener2.cc:119] All workers has initilized.
[0m[rworker.cc:47] Worker 10 on cpu 22with cor id 0
[0m[bench_listener2.cc:218] [LISTENER] receive start RPC.
[0m[rworker.cc:47] Worker 4 on cpu 8with cor id 0
[rworker.cc:47] Worker 3 on cpu 6with cor id 0
[rworker.cc:47] Worker 6 on cpu 12with cor id 0
[0m[0m[rworker.cc:47] Worker 7 on cpu 14with cor id 0
[rworker.cc:47] Worker 2 on cpu 4with cor id 0
[0m[rworker.cc:47] Worker 1 on cpu 2with cor id 0
[0m[0m[rworker.cc:47] Worker 0 on cpu 0with cor id 0
[0m[rworker.cc:47] Worker 5 on cpu 10with cor id 0
[0m[0mmerge data 63.670000 K from gorgon6
merge data 67.699000 K from gorgon7
merge data 67.740000 K from gorgon8
my throughput 67.870000 K, abort 430662, commit 67870, abort ratio 0.863860
merge data 67.870000 K from gorgon5
[occ_statistics.h:58] lock lat: 71638.4 ;counts 22894
[0m[occ_statistics.h:61] log lat: 0 ;counts 1
[0m[occ_statistics.h:64] commit lat: 56970.1 ;counts 900
[0m[occ_statistics.h:67] temp lat: 0 ;counts 1
[0m[occ_statistics.h:70] read_lat lat: 0 ;counts 1
[0m[occ_statistics.h:73] renew_lease lat: 0 ;counts 1
[0m[occ_statistics.h:77] release_read lat: 0 ;counts 1
[0m[occ_statistics.h:80] release_write lat: 41067.2 ;counts 10648
[0m@1 System throughput 266.979000 K, abort 0.861566
merge data 63.530000 K from gorgon6
merge data 67.384000 K from gorgon7
merge data 67.883000 K from gorgon8
my throughput 67.872000 K, abort 433343, commit 67872, abort ratio 0.864585
merge data 67.872000 K from gorgon5
[occ_statistics.h:58] lock lat: 69856.6 ;counts 23442
[0m[occ_statistics.h:61] log lat: 0 ;counts 1
[0m[occ_statistics.h:64] commit lat: 59379.5 ;counts 856
[0m[occ_statistics.h:67] temp lat: 0 ;counts 1
[0m[occ_statistics.h:70] read_lat lat: 0 ;counts 1
[0m[occ_statistics.h:73] renew_lease lat: 0 ;counts 1
[0m[occ_statistics.h:77] release_read lat: 0 ;counts 1
[0m[occ_statistics.h:80] release_write lat: 36891.8 ;counts 11820
[0m@2 System throughput 266.669000 K, abort 0.862408
merge data 63.283000 K from gorgon6
merge data 67.130000 K from gorgon7
merge data 67.728000 K from gorgon8
my throughput 67.899000 K, abort 423048, commit 67899, abort ratio 0.861698
merge data 67.899000 K from gorgon5
[occ_statistics.h:58] lock lat: 70846.4 ;counts 22903
[0m[occ_statistics.h:61] log lat: 0 ;counts 1
[0m[occ_statistics.h:64] commit lat: 61272.2 ;counts 818
[0m[occ_statistics.h:67] temp lat: 0 ;counts 1
[0m[occ_statistics.h:70] read_lat lat: 0 ;counts 1
[0m[occ_statistics.h:73] renew_lease lat: 0 ;counts 1
[0m[occ_statistics.h:77] release_read lat: 0 ;counts 1
[0m[occ_statistics.h:80] release_write lat: 39974.4 ;counts 11504
[0m@3 System throughput 266.040000 K, abort 0.861087
[bench_listener2.cc:260] start to exit.
[0mstats for worker 0:
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
[bench_listener2.cc:279] Medium latency 0.743012ms, 90th latency 2.42862ms, 99th latency 5.55176ms; average latency: 1.15953ms.
[0mYCSB executed 25522, latency: 1.159535, rw_size -nan, m 0.743034, 90 2.428672, 99 5.551869
succs ratio 0.140505
[bank_worker.h:126] worker exit.
[0m[bank_worker.h:129] read time: 0ms
[0m[occ_statistics.h:39] read_lat time: 0ms
[0m[occ_statistics.h:40] lock time: 0.0307717ms
[0m[occ_statistics.h:41] release_write time: 0.0170905ms
[0m[occ_statistics.h:42] renew_lease time: 0ms
[0m[occ_statistics.h:43] commit time: 0.0257403ms
[0m[occ_statistics.h:45] 0
[0m[occ_statistics.h:46] 0.0307717
[0m[occ_statistics.h:47] 0.0170905
[0m[occ_statistics.h:48] 0
[0m[occ_statistics.h:49] 0.0257403
[0m[occ_statistics.h:51] log time: 0
[0m[occ_statistics.h:52] temp time: 0ms
[0m[occ_statistics.h:53] release_read time: 0ms
[0m[bench_worker.cc:388] 0: 0
[0m[bench_worker.cc:388] 1: 141307
[0m[bench_worker.cc:388] 2: 14745
[0m[bench_worker.cc:388] 3: 0
[0m[bench_worker.cc:388] 4: 156037
[0m[bench_worker.cc:388] 5: 0
[0m[bench_worker.cc:388] 6: 0
[0m[bench_worker.cc:388] 7: 0
[0m[bench_worker.cc:388] 8: 0
[0m[bench_worker.cc:388] 9: 0
[0m[bench_worker.cc:388] 10: 0
[0m[bench_worker.cc:388] 11: 0
[0m[bench_worker.cc:388] 12: 0
[0m[bench_worker.cc:388] 13: 0
[0m[bench_worker.cc:388] 14: 0
[0m[bench_worker.cc:388] 15: 0
[0m[bench_worker.cc:388] 16: 0
[0m[bench_worker.cc:388] 17: 0
[0m[bench_worker.cc:388] 18: 0
[0m[bench_worker.cc:388] 19: 0
[0m[bench_worker.cc:388] 20: 0
[0m[bench_worker.cc:388] 21: 0
[0m[bench_worker.cc:388] 22: 0
[0m[bench_worker.cc:388] 23: 0
[0m[bench_worker.cc:388] 24: 0
[0m[bench_worker.cc:388] 25: 0
[0m[bench_worker.cc:388] 26: 0
[0m[bench_worker.cc:388] 27: 25512
[0m[bench_worker.cc:388] 28: 0
[0m[bench_worker.cc:388] 29: 0
[0m[bench_worker.cc:388] 30: 0
[0m[bench_worker.cc:388] 31: 0
[0m[bench_worker.cc:388] 32: 0
[0m[bench_worker.cc:388] 33: 0
[0m[bench_worker.cc:388] 34: 0
[0m[bench_worker.cc:388] 35: 0
[0m[bench_worker.cc:388] 36: 0
[0m[bench_worker.cc:388] 37: 0
[0m[bench_worker.cc:388] 38: 0
[0m[bench_worker.cc:388] 39: 0
[0mmaster routine exit...
[bench_listener2.cc:291] benchmark ends
[0m[bench_runner.cc:299] main runner ends.
[0m