NOCC started with program [/noccwaitdie-tcp]. at 19-08-2020 04:19:25
[bench_runner.cc:341] Use TCP port 8858
[0m[bench_runner.cc:363] use scale factor: 30; with total 10 threads.
[0m[view.h:48] Start with 2 backups.
[0m[view.cc:10] total 4 backups to assign
[0m[bank_main.cc:134] ycsb param:set len=10 write num=2tx hot90num_hot100num_accounts 100000
[0m[bank_main.cc:143] here0
[0m[Bank]: check workload 17, 17, 17, 16, 17, 16, 0
[util.cc:161] malloc_huge_pages: size = 13883146240huge_page_sz = 2097152flag = 1
[0m[util.cc:178] huge page real size 12.9316
[0m[librdma] get device name mlx5_0, idx 0
[librdma] : Device 0 has 1 ports
poller bind address tcp://*:8858
[bench_runner.cc:144] [TCP] creating shared sockets
[0m[TCP] creating shared sockets for tcp://172.23.33.33:8858
[TCP] creating shared sockets for tcp://172.23.33.34:8858
[TCP] creating shared sockets for tcp://172.23.33.35:8858
[TCP] creating shared sockets for tcp://172.23.33.32:8858
[bench_runner.cc:157] Total logger area 0.00390625G.
[0m[bench_runner.cc:167] Total two-phase committer area 0.00195312G.
[0m[bench_runner.cc:176] add RDMA store size 7.8125G.
[0m[bench_runner.cc:185] [Mem] RDMA heap size 5.10935G.
[0m[util.cc:161] malloc_huge_pages: size = 314572800huge_page_sz = 2097152flag = 1
[0m[util.cc:178] huge page real size 0.294922
[0m[util.cc:161] malloc_huge_pages: size = 314572800huge_page_sz = 2097152flag = 1
[0m[util.cc:178] huge page real size 0.294922
[0m[util.cc:161] malloc_huge_pages: size = 314572800huge_page_sz = 2097152flag = 1
[0m[util.cc:178] huge page real size 0.294922
[0m[Bank], total 12000000 accounts loaded
[bank_main.cc:344] check cv balance 46280
[0m[Runner] local db size: 276.348 MB
[Runner] DID NOT start server for receiving QP connection requests.
[Runner] Cache size: 0 MB
[util.cc:161] malloc_huge_pages: size = 1440000000huge_page_sz = 2097152flag = 1
[0m[util.cc:178] huge page real size 1.34375
[0m[util.cc:161] malloc_huge_pages: size = 1440000000huge_page_sz = 2097152flag = 1
[0m[util.cc:178] huge page real size 1.34375
[0m[util.cc:161] malloc_huge_pages: size = 1440000000huge_page_sz = 2097152flag = 1
[0m[util.cc:178] huge page real size 1.34375
[0m[Bank], total 12000000 accounts loaded
[bench_runner.cc:269] [Runner] Backup DB[0] for 2 size: 644.914 MB
[0m[util.cc:161] malloc_huge_pages: size = 1440000000huge_page_sz = 2097152flag = 1
[0m[util.cc:178] huge page real size 1.34375
[0m[util.cc:161] malloc_huge_pages: size = 1440000000huge_page_sz = 2097152flag = 1
[0m[util.cc:175] huge page alloc failed!
[0m[util.cc:161] malloc_huge_pages: size = 1440000000huge_page_sz = 2097152flag = 1
[0m[util.cc:175] huge page alloc failed!
[0m[Bank], total 12000000 accounts loaded
[bench_runner.cc:269] [Runner] Backup DB[1] for 3 size: 645.121 MB
[0mworker: 0 binding 0
worker: 1 binding 2
worker: 2 binding 4
worker: 3 binding 6
worker: 4 binding 8
worker: 5 binding 10
worker: 6 binding 12
worker: 7 binding 14
worker: 8 binding 16
worker: 9 binding 18
[Global sequence running] !
[bench_listener2.cc:70] try log results to ./results//noccwaitdie-tcp_bank_4_10_1_100.log
[0m[NOCC] poller running!
[bench_worker.h:156] Use RPC for logging.
[0m[rworker.cc:47] Worker 11 on cpu 20with cor id 0
[0mWAITDIE uses RPC LOCK.
WAITDIE uses RPC LOG.
WAITDIE uses RPC RELEASE.
WAITDIE uses RPC COMMIT.
[bench_listener2.cc:79] New monitor running!
[0m[bench_listener2.cc:130] All workers has initilized.
[0m[rworker.cc:47] Worker 12 on cpu 7with cor id 0
[0m[bench_listener2.cc:135] Starting Master Listener.
[0m[bench_listener2.cc:234] [LISTENER] receive start RPC.
[0m[rworker.cc:47] Worker 7 on cpu 14with cor id 0
[0m[rworker.cc:47] Worker 4 on cpu 8with cor id 0
[0m[rworker.cc:47] Worker 0 on cpu 0with cor id 0
[0m[rworker.cc:47] Worker 6 on cpu 12with cor id 0
[0m[rworker.cc:47] Worker 9 on cpu 18with cor id 0
[0m[rworker.cc:47] Worker 5 on cpu 10with cor id 0
[0m[rworker.cc:47] Worker 3 on cpu 6with cor id 0
[0m[rworker.cc:47] Worker 2 on cpu 4with cor id 0
[0m[rworker.cc:47] Worker 1 on cpu 2with cor id 0
[0m[rworker.cc:47] Worker 8 on cpu 16with cor id 0
[0mmerge data 3.227000 K from gorgon5
merge data 2.720000 K from gorgon2
merge data 2.652000 K from gorgon4
my throughput 2.663000 K, abort 0, commit 2663, abort ratio 0.000000
merge data 2.663000 K from gorgon3
[occ_statistics.h:111] lock lat: 1.13371e+06 ;counts 507
[0m[occ_statistics.h:114] lock cpu cycles: 4.56607 ;counts 507
[0m[occ_statistics.h:117] validate lat: 0 ;counts 1
[0m[occ_statistics.h:120] validate cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:123] log lat: 3.24143e+06 ;counts 223
[0m[occ_statistics.h:126] log cpu cycles: 17.0493 ;counts 223
[0m[occ_statistics.h:129] twopc lat: 0 ;counts 1
[0m[occ_statistics.h:132] twopc cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:135] commit lat: 968938 ;counts 269
[0m[occ_statistics.h:138] commit cpu cycles: 0.446097 ;counts 269
[0m[occ_statistics.h:141] temp lat: 0 ;counts 1
[0m[occ_statistics.h:144] temp cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:147] read_lat lat: 0 ;counts 1
[0m[occ_statistics.h:150] read cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:153] renew_lease lat: 0 ;counts 1
[0m[occ_statistics.h:156] renew_lease cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:159] release_read lat: 0 ;counts 1
[0m[occ_statistics.h:162] release_read cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:165] release_write lat: 224370 ;counts 269
[0m[occ_statistics.h:168] release_write cpu cycles: 13.7509 ;counts 269
[0m@1 System throughput 11.262000 K, abort 0.000710
merge data 5.351000 K from gorgon5
merge data 5.054000 K from gorgon2
merge data 5.631000 K from gorgon4
my throughput 5.286000 K, abort 0, commit 5286, abort ratio 0.000000
merge data 5.286000 K from gorgon3
[occ_statistics.h:111] lock lat: 823246 ;counts 977
[0m[occ_statistics.h:114] lock cpu cycles: 1.8881e+16 ;counts 977
[0m[occ_statistics.h:117] validate lat: 0 ;counts 1
[0m[occ_statistics.h:120] validate cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:123] log lat: 1.25533e+06 ;counts 440
[0m[occ_statistics.h:126] log cpu cycles: 4.37273 ;counts 440
[0m[occ_statistics.h:129] twopc lat: 0 ;counts 1
[0m[occ_statistics.h:132] twopc cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:135] commit lat: 656898 ;counts 533
[0m[occ_statistics.h:138] commit cpu cycles: 18.9981 ;counts 533
[0m[occ_statistics.h:141] temp lat: 0 ;counts 1
[0m[occ_statistics.h:144] temp cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:147] read_lat lat: 0 ;counts 1
[0m[occ_statistics.h:150] read cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:153] renew_lease lat: 0 ;counts 1
[0m[occ_statistics.h:156] renew_lease cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:159] release_read lat: 0 ;counts 1
[0m[occ_statistics.h:162] release_read cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:165] release_write lat: 233747 ;counts 533
[0m[occ_statistics.h:168] release_write cpu cycles: 3.46093e+16 ;counts 533
[0m@2 System throughput 21.322000 K, abort 0.000000
merge data 5.972000 K from gorgon5
merge data 5.824000 K from gorgon2
merge data 6.036000 K from gorgon4
my throughput 6.120000 K, abort 0, commit 6120, abort ratio 0.000000
merge data 6.120000 K from gorgon3
[occ_statistics.h:111] lock lat: 648299 ;counts 1127
[0m[occ_statistics.h:114] lock cpu cycles: 1.79592 ;counts 1127
[0m[occ_statistics.h:117] validate lat: 0 ;counts 1
[0m[occ_statistics.h:120] validate cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:123] log lat: 1.06885e+06 ;counts 516
[0m[occ_statistics.h:126] log cpu cycles: 3.57495e+16 ;counts 516
[0m[occ_statistics.h:129] twopc lat: 0 ;counts 1
[0m[occ_statistics.h:132] twopc cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:135] commit lat: 661127 ;counts 612
[0m[occ_statistics.h:138] commit cpu cycles: 3.01417e+16 ;counts 612
[0m[occ_statistics.h:141] temp lat: 0 ;counts 1
[0m[occ_statistics.h:144] temp cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:147] read_lat lat: 0 ;counts 1
[0m[occ_statistics.h:150] read cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:153] renew_lease lat: 0 ;counts 1
[0m[occ_statistics.h:156] renew_lease cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:159] release_read lat: 0 ;counts 1
[0m[occ_statistics.h:162] release_read cpu cycles: 0 ;counts 1
[0m[occ_statistics.h:165] release_write lat: 194380 ;counts 612
[0m[occ_statistics.h:168] release_write cpu cycles: 11.4788 ;counts 612
[0m@3 System throughput 23.952000 K, abort 0.000000
[bench_listener2.cc:276] start to exit.
[0mstats for worker 0:
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
exiting master routine.
[NOCC] poller exit!
exiting master routine.
SendPayment executed 258, latency: 2.566323, rw_size -nan, m 1.710313, 90 2.640050, 99 21.293604
DepositChecking executed 219, latency: 2.026426, rw_size -nan, m 1.361714, 90 1.984775, 99 18.268732
Balance executed 235, latency: 0.989631, rw_size -nan, m 0.813315, 90 1.393007, 99 8.445848
Transact saving executed 229, latency: 1.929940, rw_size -nan, m 1.323332, 90 2.218739, 99 19.173962
Write check executed 245, latency: 2.426965, rw_size -nan, m 1.946956, 90 2.608557, 99 22.120668
Txn amal executed 229, latency: 2.737113, rw_size -nan, m 2.041546, 90 3.036006, 99 15.755656
succs ratio 0.999293
[bank_worker.h:126] worker exit.
[0m[bench_listener2.cc:295] Medium latency 1.53694ms, 90th latency 2.47893ms, 99th latency 19.7218ms; average latency: 2.12055ms.
[0m[bank_worker.h:129] read time: 0ms
[0m[occ_statistics.h:63] read_lat time: 0ms
[0m[occ_statistics.h:64] lock time: 0.377551ms
[0m[occ_statistics.h:65] release_write time: 0.0945592ms
[0m[occ_statistics.h:66] release_read time: 0ms
[0m[occ_statistics.h:67] renew_lease time: 0ms
[0m[occ_statistics.h:68] validate time: 0ms
[0m[occ_statistics.h:69] log time: 0.806563ms
[0m[occ_statistics.h:70] 2pc time: 0ms
[0m[occ_statistics.h:71] commit time: 0.331424ms
[0m[occ_statistics.h:73] 0
[0m[occ_statistics.h:74] 0.377551
[0m[occ_statistics.h:75] 0.0945592
[0m[occ_statistics.h:76] 0
[0m[occ_statistics.h:77] 0.331424
[0m[occ_statistics.h:80] temp time: 0ms
[0m[occ_statistics.h:97] read cpu time: 0ms
[0m[occ_statistics.h:98] lock cpu time: 2.73622e+09ms
[0m[occ_statistics.h:99] release_write cpu time: 5.01554e+09ms
[0m[occ_statistics.h:100] release_read cpu time: 0ms
[0m[occ_statistics.h:101] renew_lease cpu time: 0ms
[0m[occ_statistics.h:102] validate cpu time: 0ms
[0m[occ_statistics.h:103] log cpu time: 5.18078e+09ms
[0m[occ_statistics.h:104] 2pc cpu time: 0ms
[0m[occ_statistics.h:105] commit cpu time: 4.36811e+09ms
[0m[occ_statistics.h:106] temp time: 0ms
[0m[bench_worker.cc:392] 0: 0
[0m[bench_worker.cc:392] 1: 0
[0m[bench_worker.cc:392] 2: 0
[0m[bench_worker.cc:392] 3: 0
[0m[bench_worker.cc:392] 4: 0
[0m[bench_worker.cc:392] 5: 0
[0m[bench_worker.cc:392] 6: 0
[0m[bench_worker.cc:392] 7: 0
[0m[bench_worker.cc:392] 8: 0
[0m[bench_worker.cc:392] 9: 0
[0m[bench_worker.cc:392] 10: 0
[0m[bench_worker.cc:392] 11: 0
[0m[bench_worker.cc:392] 12: 0
[0m[bench_worker.cc:392] 13: 0
[0m[bench_worker.cc:392] 14: 0
[0m[bench_worker.cc:392] 15: 0
[0m[bench_worker.cc:392] 16: 0
[0m[bench_worker.cc:392] 17: 0
[0m[bench_worker.cc:392] 18: 7798
[0m[bench_worker.cc:392] 19: 715
[0m[bench_worker.cc:392] 20: 0
[0m[bench_worker.cc:392] 21: 0
[0m[bench_worker.cc:392] 22: 0
[0m[bench_worker.cc:392] 23: 0
[0m[bench_worker.cc:392] 24: 0
[0m[bench_worker.cc:392] 25: 0
[0m[bench_worker.cc:392] 26: 1414
[0m[bench_worker.cc:392] 27: 0
[0m[bench_worker.cc:392] 28: 0
[0m[bench_worker.cc:392] 29: 0
[0m[bench_worker.cc:392] 30: 0
[0m[bench_worker.cc:392] 31: 0
[0m[bench_worker.cc:392] 32: 0
[0m[bench_worker.cc:392] 33: 0
[0m[bench_worker.cc:392] 34: 0
[0m[bench_worker.cc:392] 35: 0
[0m[bench_worker.cc:392] 36: 0
[0m[bench_worker.cc:392] 37: 0
[0m[bench_worker.cc:392] 38: 0
[0m[bench_worker.cc:392] 39: 0
[0mmaster routine exit...
[bench_listener2.cc:307] benchmark ends
[0m[bench_runner.cc:313] main runner ends.
[0m